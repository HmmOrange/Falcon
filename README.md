# Falcon - Player Churn Prediction

This project trains a LightGBM model to predict player churn at certain game levels based on their historical data. The workflow involves preparing a sequential dataset from raw event data and then training a classifier with cross-validation.

## Project Structure

- `data/`: Placeholder directory intended for raw and processed data.
- `model/`: Placeholder directory for storing final, production-ready model artifacts.
- `src/`: Contains the main source code.
  - `prepare_data.py`: Script to process raw CSV event data into feature matrices (`.npy` files) suitable for training.
  - `train.py`: Script to train the LightGBM model using the data generated by `prepare_data.py`.
- `config.yaml`: A centralized configuration file for managing all parameters for both data preparation and model training, including file paths, model hyperparameters, and feature engineering settings.
- `requirements.txt`: A list of all Python dependencies required to run the project.

## Setup

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/duon9/Falcon.git
    cd Falcon
    ```

2.  **Install dependencies:**
    It is recommended to use a virtual environment.
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```
    Install the required Python packages using pip:
    ```bash
    pip install -r requirements.txt
    ```

## Usage

The project is run in two main stages: data preparation and model training.

### 1. Prepare Data

This step processes the raw player event data into a format ready for training.

- **Configuration**: Before running, ensure the paths and parameters in the `PREPARE_DATA` section of `config.yaml` are set correctly. You will need to provide the `INPUT_CSV_PATH` and `MEAN_TIME_PATH` which in the /data
- **Run the script**:
  ```bash
  python src/prepare_data.py
  ```
- **Output**: This will generate `X_train.npy`, `y_train.npy`, `groups_train.npy` and corresponding holdout set files in the directory specified by `OUTPUT_DIR` in the configuration.

### 2. Train Model

This step uses the prepared data to train and evaluate the LightGBM model.

- **Configuration**: Review the `TRAINING`, `LGB_PARAMS`, and `MLFLOW` sections in `config.yaml` to set hyperparameters and experiment details.
- **Run the script**:
  ```bash
  python src/train.py
  ```
- **Output**:
    - The script will train a cross-validated LightGBM model.
    - All parameters, metrics, and model artifacts (for each fold) will be logged to MLflow. You can view the results by running `mlflow ui` in the terminal and navigating to the displayed URL.
    - Final predictions and feature importances will be saved to the `OUTPUT_DIR`.

### 3. Serve Model

This step runs a FastAPI server to serve the trained model for real-time predictions.

- **Run the server**:
  ```bash
  uvicorn serve.app:app --reload --host 0.0.0.0 --port 8000
  ```
- **API Endpoint**: The server provides a `/predict` endpoint that accepts `POST` requests.
- **Input Format**: The request body should be a JSON object containing:
    - `history`: A list of the last 10 game events for a player. Each event must include `status` (float), `duration` (float), and `level` (int).
    - `target_levels`: A list of future levels for which churn predictions are desired.
- **Example Request** (`POST /predict`):
  ```json
  {
    "history": [
      {"status": 1.0, "duration": 120.5, "level": 1},
      {"status": 1.0, "duration": 150.2, "level": 2},
      {"status": 0.0, "duration": 300.0, "level": 3},
      {"status": 1.0, "duration": 180.7, "level": 4},
      {"status": 1.0, "duration": 210.1, "level": 5},
      {"status": 1.0, "duration": 195.8, "level": 6},
      {"status": 0.0, "duration": 400.0, "level": 7},
      {"status": 1.0, "duration": 250.3, "level": 8},
      {"status": 1.0, "duration": 280.9, "level": 9},
      {"status": 1.0, "duration": 300.5, "level": 10}
    ],
    "target_levels": [11, 12, 15]
  }
  ```
- **Output**: The server returns a JSON object with a `predictions` key, containing a list of churn probabilities corresponding to the `target_levels`.
  ```json
  {
    "predictions": [0.15, 0.25, 0.6]
  }
  ```
